{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18e31c0-e87f-4be9-ab18-212e3cbe8bd2",
   "metadata": {},
   "source": [
    "## This is an example of how to calculate measures for continuous quantitative data, including position, dispersion and shape measures, using Python, Pandas, NumPy and Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f9d99-67e1-4178-b518-cf9d8c0f2fbd",
   "metadata": {},
   "source": [
    "* the formulas shown at this notebook have been taken from the following reference:<br>\n",
    "FÁVERO, L. P.; BELFIORE, P. **Manual de Análise de Dados: Estatística e Machine Learning com Excel®, SPSS®, Stata®, R® e Python®**. 2ª edição, 1288 p. Brasil: ccGEN LTC, 2024.<br>\n",
    "Available in Brazil at:<br>\n",
    "https://www.amazon.com.br/Manual-An-C3-A1lise-Dados-Estat-C3-ADstica-Learning-dp-8595159920/dp/8595159920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "c5fedcab-dc4d-45ef-b2ff-015fa6d7c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libs and setting default plot style\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "22b09cbe-0f14-4c97-90fb-8335a962715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ITEM_ID  PRICE (US$)\n",
      "0         1        189.0\n",
      "1         2        195.0\n",
      "2         3        199.0\n",
      "3         4        189.0\n",
      "4         5        197.0\n",
      "..      ...          ...\n",
      "95       96        189.0\n",
      "96       97        179.0\n",
      "97       98        189.0\n",
      "98       99        199.0\n",
      "99      100        195.0\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# importing data into a Pandas Dataframe\n",
    "item_price_dataframe = pd.read_csv(\"item-price.csv\")\n",
    "# displaying head() and tail() altogether\n",
    "from pandas import option_context\n",
    "with option_context('display.max_rows', 10):\n",
    "    print(item_price_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44a5f7-9b2c-47b4-aa8b-797b911061ad",
   "metadata": {},
   "source": [
    "### Position measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c95bbe-32bd-47ba-bc89-f03929677f3a",
   "metadata": {},
   "source": [
    "#### - Arithmetic Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba29e28-6cd1-4eb3-8d24-e533d605db27",
   "metadata": {},
   "source": [
    "![mean](mean.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "c8e3f4e7-7896-4343-b6b6-1da629f6d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_price_ndarray =\n",
      "[189 195 199 189 197 189 199 202 199 209 189 179 175 199 205 219 229 205\n",
      " 190 179 199 189 183 199 206 215 149 189 169 179 159 199 195 189 209 196\n",
      " 189 165 170 179 170 175 169 189 195 199 199 199 189 182 199 209 229 199\n",
      " 195 199 179 169 189 205 199 189 189 199 179 189 239 215 199 179 195 199\n",
      " 209 205 179 185 179 169 179 189 199 209 169 159 179 185 189 179 199 199\n",
      " 189 169 159 169 209 189 179 189 199 195]\n",
      "dtype = 'int64'\n",
      "shape = (100,) => d0 = 100\n",
      "dimensions = 1\n",
      "size = 100\n"
     ]
    }
   ],
   "source": [
    "# copying the data from the \"PRICE (US$)\" column of the item_price_dataframe to an ndarray of 1 dimension (1D) and transforming the data \n",
    "# from float to int type (to facilitate calculation)\n",
    "item_price_ndarray = item_price_dataframe[\"PRICE (US$)\"].to_numpy('int64')\n",
    "print(f\"item_price_ndarray =\\n{item_price_ndarray}\")\n",
    "print(f\"dtype = '{item_price_ndarray.dtype}'\")\n",
    "print(f\"shape = {item_price_ndarray.shape} => d0 = {item_price_ndarray.shape[0]}\")\n",
    "print(f\"dimensions = {item_price_ndarray.ndim}\")\n",
    "print(f\"size = {item_price_ndarray.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "47152f4e-f32b-485d-b94f-12cec1433969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as it is a 1-dimension ndarray, specifying the axis for operations is optional - the axis of 1D ndarrays is always axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "8042a21b-b740-49ea-8035-30cf25db2886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190.77"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the mean value\n",
    "arithmetic_mean = np.sum(a=item_price_ndarray, axis=0)/np.size(a=item_price_ndarray)\n",
    "arithmetic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "704056b1-aed6-4af4-8762-db6fce512286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "92d4d065-f294-4174-a482-16713eb7557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190.77"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the mean value\n",
    "arithmetic_mean = np.mean(a=item_price_ndarray, axis=0)\n",
    "arithmetic_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1c051-d966-423a-ac9b-6be8244112a5",
   "metadata": {},
   "source": [
    "#### - Median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141278c-6ab0-4983-86de-17f59c1e6ca4",
   "metadata": {},
   "source": [
    "![median](median.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c26ca8ed-1015-4653-94c5-cb382f392fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149, 159, 159, 159, 165, 169, 169, 169, 169, 169, 169, 169, 170,\n",
       "       170, 175, 175, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179,\n",
       "       179, 179, 179, 182, 183, 185, 185, 189, 189, 189, 189, 189, 189,\n",
       "       189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189,\n",
       "       190, 195, 195, 195, 195, 195, 195, 196, 197, 199, 199, 199, 199,\n",
       "       199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199,\n",
       "       199, 199, 199, 199, 202, 205, 205, 205, 205, 206, 209, 209, 209,\n",
       "       209, 209, 209, 215, 215, 219, 229, 229, 239])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the item_price_ndarray for calculating the median\n",
    "sorted_item_price_ndarray = np.sort(a=item_price_ndarray)\n",
    "sorted_item_price_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f838f788-5816-4296-bcf1-5592d32159be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189.0"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resetting variable for avoiding cache issues\n",
    "median = np.nan\n",
    "# calculating the median\n",
    "# when number of elements is odd\n",
    "if(sorted_item_price_ndarray.size % 2 != 0):\n",
    "    position_index_of_median_value = int((sorted_item_price_ndarray.size+1)/2)\n",
    "    median = sorted_item_price_ndarray[position_index_of_median_value]\n",
    "    # print(f\"pos = ({sorted_item_price_ndarray.size}+1)/2={position_index_of_median_value}\")\n",
    "# when number of elements is even\n",
    "else:\n",
    "    position_index_of_median_value_1 = int(sorted_item_price_ndarray.size/2)\n",
    "    position_index_of_median_value_2 = int(sorted_item_price_ndarray.size/2+1)\n",
    "    median = (sorted_item_price_ndarray[position_index_of_median_value_1]+sorted_item_price_ndarray[position_index_of_median_value_2])/2\n",
    "    # print(f\"({sorted_item_price_ndarray[position_index_of_median_value_1]}+{sorted_item_price_ndarray[position_index_of_median_value_2]})/2=\")\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "0677ec8c-3016-44ca-b8e9-265846d060b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "7a743f8a-3c7b-4c5d-9ba7-f0df42bcda7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189.0"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if using the median method of NumPy, no need to sort the ndarray (it is sorted automatically, inside the method)\n",
    "# calculating the median\n",
    "np.median(a=item_price_ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05563368-2e6d-4d06-8789-3e366dafb452",
   "metadata": {},
   "source": [
    "#### - Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f5957521-63cd-486d-bbb3-04ed09e1b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the single modal number\n",
    "def get_single_mode(number_list):\n",
    "    # sorting the received number list (in case it is not yet sorted)\n",
    "    sorted_number_list = sorted(number_list)\n",
    "    # creating a dict structure for temporarily storing each unique number along with its ocurrences at the reveived number_list\n",
    "    number_count_dictionary={}\n",
    "    for number in sorted_number_list:\n",
    "        # if the unique number is not yet present at the number_count_dictionary, add it and set occurences count to 1\n",
    "        if not number in number_count_dictionary:\n",
    "            number_count_dictionary[number]=1\n",
    "        # if the unique number is already present, increment in 1 the existing occurences count\n",
    "        else:\n",
    "            number_count_dictionary[number]+=1\n",
    "    # print(f\"number_count_dictionary =\\n{number_count_dictionary}\\n\")\n",
    "    # print(f\"{number_count_dictionary.items()}\\n\")\n",
    "    # print(f\"{number_count_dictionary.keys()}\\n\")\n",
    "    # print(f\"{number_count_dictionary.values()}\\n\")\n",
    "    # print(f\"{len(number_count_dictionary.items())} unique numbers\\n\")\n",
    "    # # inversely sorting number_count_dictionary according to items values (occurences count), so that the first item will contain the\n",
    "    # # number which occurs the most, along with its occurences count\n",
    "    # number_count_tuple_list_by_count_reversed = sorted(number_count_dictionary.items(), key=lambda x:x[1])[::-1]\n",
    "    # print(f\"number_count_tuple_list_by_count_reversed =\\n{number_count_tuple_list_by_count_reversed}\\n\")\n",
    "    # # getting the modal tuple: (modal number,number occurences) - the first tuple a the ordered dict above\n",
    "    # single_mode_tuple = number_count_tuple_list_by_count_reversed[0]\n",
    "    # print(f\"single_mode_tuple = {single_mode_tuple}\\n\")\n",
    "    # # getting the single modal number and its occurences count from the single_mode_tuple\n",
    "    # mode = single_mode_tuple[0]\n",
    "    # count = single_mode_tuple[1]\n",
    "    # print(f\"single_mode is {mode} with {count} occurrences\")\n",
    "    # using a list comprehension to return a list with the modal number, from the modal tuple, from the dict items, when the tuple has \n",
    "    # the max number of occurences count (therefore also the respective modal number), and returning the modal number from the list\n",
    "    return [number for number,occurences in number_count_dictionary.items() if occurences==max(number_count_dictionary.values())][0]\n",
    "\n",
    "get_single_mode(item_price_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "60ccb50e-3190-4584-8187-8ff4ded2be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "375a9467-c39c-42d3-a212-8da7807437f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the single modal number\n",
    "def get_single_mode_2(number_list):\n",
    "    # print(f\"original number_list\\t\\t= {number_list}\\n\")\n",
    "    # using numpy unique() method to return a tuple with two arrays, the first being the sorted_unique_numbers and the other\n",
    "    # being the respective counts of occurrences for each of these numbers. The indexes are the same for each number at one\n",
    "    # array and its respective occurence count pair at the other. If we get the index for the max occurence count at the 2nd array, \n",
    "    # we also get the index for the modal number at the 1st array - the index is the same\n",
    "    sorted_unique_numbers_list, occurences_of_each_number_list = np.unique(number_list, return_counts=True)\n",
    "    # print(f\"sorted_unique_numbers_list\\t= {sorted_unique_numbers_list}\\n\")\n",
    "    # print(f\"occurences_of_each_number_list\\t= {occurences_of_each_number_list}\\n\")\n",
    "    # getting the index for the max occurence count value at occurences_of_each_number_list\n",
    "    max_occurence_index = np.argmax(occurences_of_each_number_list)\n",
    "    # print(f\"max_occurence_index = {max_occurence_index}\\n\")\n",
    "    # with that index, it's then possible to get the values for both the modal number at one array as for its occurences count at\n",
    "    # the other array - the index is the same\n",
    "    mode = sorted_unique_numbers_list[max_occurence_index]\n",
    "    mode_occurrences = occurences_of_each_number_list[max_occurence_index]\n",
    "    # print(f\"single_mode is {mode} with {mode_occurrences} occurrences\\n\")\n",
    "    return mode\n",
    "\n",
    "get_single_mode_2(item_price_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "a746770e-ba1f-47d7-95ee-e98fc5e9ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7ccaebd2-4b53-4709-816f-27e4d9b9fb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the single modal number\n",
    "# using module stats from module scipy to get the modal tuple and extract both the modal number and its occurences count from this tuple\n",
    "from scipy import stats\n",
    "mode_tuple = stats.mode(item_price_ndarray)\n",
    "# print(f\"single_mode is {mode_tuple[0]} with {mode_tuple[1]} occurrences\\n\")\n",
    "mode_tuple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "550231f8-165c-4bb4-80bb-1ce248e812e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "fd25ad9e-97bf-4fbf-a0d7-afdbb6ebb5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using module statistics to get the modal number and then count its occurences at the item_price_ndarray\n",
    "import statistics\n",
    "mode = statistics.mode(item_price_ndarray)\n",
    "count = item_price_ndarray.tolist().count(mode)\n",
    "# print(f\"single_mode is {mode} with {count} occurrences\\n\")\n",
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "78d308b6-14a4-42d6-a9aa-c7415ceef67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "5e9631f2-c426-4e91-be75-e148611f8a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using class Counter from module collections to get a dictionary having as keys the modal number and as paired values the count of \n",
    "# occurences of the modal number occurences at the item_price_ndarray\n",
    "from collections import Counter\n",
    "counting_dictionary = Counter(item_price_ndarray)\n",
    "# getting the max occurences count from the list of values from the counting_dictionary\n",
    "count = np.max(list(counting_dictionary.values()))\n",
    "# getting the corresponding key (modal number) for that max value (occurences count) - when both keys and values of the \n",
    "# counting_dictionary are converted to lists, the index for respective keys and values is the same\n",
    "# In this case, the common index is gotten from the max occurences count value and then used to get the modal number at the other list -\n",
    "# the index is the same\n",
    "mode = list(counting_dictionary.keys())[list(counting_dictionary.values()).index(count)]\n",
    "# print(f\"single_mode is {mode} with {count} occurrences\\n\")\n",
    "mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde58cc-e87a-42f6-9cc8-a6b5373cea4b",
   "metadata": {},
   "source": [
    "#### - Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "9a855029-5c38-41ef-94d3-e7e07782e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use percentiles formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262d358-d025-43c9-be43-19e9d1f714a1",
   "metadata": {},
   "source": [
    "#### - Deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "660ae092-f9f2-4959-aab8-dd5cafc054d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use percentiles formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89fca10-9f59-4fdd-9d19-e244a4d7e710",
   "metadata": {},
   "source": [
    "#### - Percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e6dff-d7aa-426f-a448-189c536f0d53",
   "metadata": {},
   "source": [
    "![percentile](percentile.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "be6f9497-0797-4dcd-97db-ecbf5b4b504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.0"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a percentile function for getting any kind of percentile, including median, quartile, decile, etc.\n",
    "# k_score is the k-th score or centile, e.g., for median it's 50 (from 50th percentile), for 1st Quartile it's 25 (from 25th percentile),\n",
    "# for 3rd decile it's 30 (from 30th percentile), etc.\n",
    "import math\n",
    "def get_percentile(k_score, number_list):\n",
    "    # sorting the input number_list\n",
    "    sorted_number_list = sorted(number_list)\n",
    "    # calculating n\n",
    "    n = len(sorted_number_list)\n",
    "    # calculating the position index, which the percentile result corresponds to, at the sorted_number_list (as arrays start at 0, gotta\n",
    "    # subtract 1 at the end to get the right position at ndarrays (when compared to other book formulas, whose arrays start at 1)\n",
    "    pos = ((n-1)*k_score/100)+1-1\n",
    "    # if the pos index is not an integer, but a float, the percentile result is a value between two numbers at the list. At this particular \n",
    "    # case, a ponderation is done, considering the integer part of the pos index as the index on the left and the subsequent index as \n",
    "    # the index on the right, each of these with its respective values (numbers) at the sorted_number_list. The number value corresponding \n",
    "    # to the index on the left is multiplied by the complement of the decimal part and added to the product of the number value \n",
    "    # corresponding to the index on the right multiplied by the decimal part. That way, the percentile number value is calculated between\n",
    "    # two corresponding number values, with the right ponderation regarding the final number value.\n",
    "    if(not isinstance(pos, int)):\n",
    "        decimal_part, integer_part = math.modf(pos)\n",
    "        integer_part = int(integer_part)\n",
    "        return (sorted_number_list[integer_part]*(1-decimal_part)+sorted_number_list[integer_part+1]*(decimal_part))\n",
    "    # whereas, if the pos index is an integer, then it is the only index needed to fetch the percentile number value directly at the \n",
    "    # sorted_number_list. No need for any ponderation or aditional calculations\n",
    "    else:\n",
    "        return sorted_number_list[pos]\n",
    "\n",
    "# getting the 1st quartile, which is the same as 25th percentile\n",
    "# get_percentile(25,item_price_ndarray)\n",
    "# getting the 2nd quartile, which is the same as 50th percentile or median\n",
    "# get_percentile(50,item_price_ndarray)\n",
    "# getting the 3rd quartile, which is the same as 75th percentile\n",
    "get_percentile(75,item_price_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "a537cfa7-1c55-4e91-9357-620de8c12e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "94d691f1-dfcd-4868-ae9d-6e035729d9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.0"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the 1st quartile, which is the same as 25th percentile\n",
    "# np.percentile(a=item_price_ndarray, q=25)\n",
    "# getting the 2nd quartile, which is the same as 50th percentile or median\n",
    "# np.percentile(a=item_price_ndarray, q=50)\n",
    "# getting the 3rd quartile, which is the same as 75th percentile\n",
    "np.percentile(a=item_price_ndarray, q=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be5753-e1d7-4dcb-839a-419e1eab9aee",
   "metadata": {},
   "source": [
    "### Dispersion measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e47663-2dc1-4c41-8846-04ac9c870e58",
   "metadata": {},
   "source": [
    "#### - Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "18d9836f-9ea0-4740-8af4-5fdcfdc251a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_range(number_list):\n",
    "    return np.max(number_list) - np.min(number_list)\n",
    "\n",
    "get_range(item_price_ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34016f-f145-481d-9d61-d71169ffa842",
   "metadata": {},
   "source": [
    "#### - Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22fd23-a93b-4ca5-b940-7e4f20702125",
   "metadata": {},
   "source": [
    "![sample-variance](sample-variance.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "79a9febd-c4d4-4e6e-8f68-78a7c244b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In short, variance is a dispersion measure that reflects how far each random value of a distribution is from the arithmetic mean of that\n",
    "# distribution. If the variance is a population variance, it's calculated by dividing the sum of squares of the differences between each \n",
    "# value of the population analysed and the arithmetic mean by N, being N the number of TOTAL individuals at that analysed population. \n",
    "# If, on the other hand, the case is of a sample variance, that is, an estimate of the plation variance - when you don't have all data \n",
    "# available from the considered population, but only part of it, this sample variance is calculated the same way but, instead of N at the\n",
    "# denominator, it's used (n-1), where n is the sample number, instead of the population number. The equation above is of a sample variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "c5069b02-a1cc-4909-a3bf-65a88dbf11ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_variance = 244.02 --- population_variance = 241.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "244.02"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating both population and sample variances for the data in item_price_ndarray\n",
    "my_mean = np.mean(item_price_ndarray)\n",
    "my_n = len(item_price_ndarray)\n",
    "\n",
    "def calculate_variance(number_list, sample=False):\n",
    "    accumulator = 0\n",
    "    for number in number_list:\n",
    "        accumulator += np.square(number-my_mean)\n",
    "    if(sample):\n",
    "        return accumulator/(my_n-1)\n",
    "    else:\n",
    "        return accumulator/(my_n)\n",
    "\n",
    "print(f\"sample_variance = {round(calculate_variance(item_price_ndarray, True),2)} --- population_variance = {round(calculate_variance(item_price_ndarray, False),2)}\")\n",
    "\n",
    "round(calculate_variance(item_price_ndarray, sample=True),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "99c7fdc1-e466-40e5-8d48-75e1107bad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c0a2f579-c4ac-4fc8-978d-df63e6e12636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_variance = 244.02 --- population_variance = 241.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "244.02"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating both population and sample variances for the data in item_price_ndarray\n",
    "# the np method is the same var(), except for the setting of the parameter \"ddof\" (from Delta Degrees of Freedom) as 1, which is the factor \n",
    "# to be subtracted from the denominator N of the equation (turning into \"n-1\"), in case you want to calculate the estimation of variance \n",
    "# using a sample and not the whole considered population. By default ddof=0, and the denominator is only the N, assuming the array has all\n",
    "# elements of distribution at the whole analysed population - population variance.\n",
    "# Below both variances are calculated and rounded to 2 decimals.\n",
    "population_variance = np.round(np.var(a=item_price_ndarray), 2)\n",
    "sample_variance = np.round(np.var(a=item_price_ndarray, ddof=1), 2)\n",
    "print(f\"sample_variance = {sample_variance} --- population_variance = {population_variance}\")\n",
    "sample_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5e0ae-20b2-4dd4-bb53-be50fb757e02",
   "metadata": {},
   "source": [
    "#### - Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc387a-9c95-406b-9d8e-c8ef8eb7f205",
   "metadata": {},
   "source": [
    "![standard deviation](standard_deviation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "1e31d37f-06af-4b6e-8501-f2ca06d67c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation is another dispersion measure and is simply the square root of the variance of a certain data distribution, with a \n",
    "# better interpretability, as, differently from variance, the standard deviation has the same units as the original data at the distribution\n",
    "# therefore, we can estimate the difference between random values at a certain distribution and the mean of that distribution, using the \n",
    "# same units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "3c956a3b-64e8-498f-8163-351f371afc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_standard_deviation = 15.62 --- population_standard_deviation = 15.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.62"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating both population and sample standard_deviation (sd) for the data in item_price_ndarray\n",
    "population_standard_deviation = np.round(np.sqrt(calculate_variance(item_price_ndarray)), 2)\n",
    "sample_standard_deviation = np.round(np.sqrt(calculate_variance(item_price_ndarray, True)), 2)\n",
    "print(f\"sample_standard_deviation = {sample_standard_deviation} --- population_standard_deviation = {population_standard_deviation}\")\n",
    "sample_standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "12b2bf09-64d4-4927-9fae-70b957e91505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "ae4f6c7a-828c-40a4-a513-39272efaa802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_standard_deviation = 15.62 --- population_standard_deviation = 15.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.62"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating both population and sample standard_deviation (sd) for the data in item_price_ndarray\n",
    "population_standard_deviation = np.round(np.std(a=item_price_ndarray), 2)\n",
    "sample_standard_deviation = np.round(np.std(a=item_price_ndarray, ddof=1), 2)\n",
    "print(f\"sample_standard_deviation = {sample_standard_deviation} --- population_standard_deviation = {population_standard_deviation}\")\n",
    "sample_standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a51a0-a94c-4443-9ec3-4b2ab96b67f7",
   "metadata": {},
   "source": [
    "#### - Standard Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac914d7-5c34-4bc5-a338-be7d7b8711a0",
   "metadata": {},
   "source": [
    "![sample standard error](sample_standard_error.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "63bc44cc-3d35-46c8-b1b4-cbcbb96b770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard error is yet another dispersion measure, which is the standard deviation divided by the square root of the \n",
    "# number of elements n - both regarding the whole considered population or a sample of it: that is, precise population \n",
    "# standard error or estimated sample standard error, similar to variance and standard deviation above. Standard error\n",
    "# is the standard deviation of the mean, that is, how precise the mean is when calculated multiple times at that same\n",
    "# population or sample, giving an idea of probability that the may means calculated will be within a certain error range,\n",
    "# which can be reported right on the side of the mean (e.g. mean = 550 +- 12.8 (SE)) or included at the confidence \n",
    "# interval (e.g. for 95% of confidence interval, CI = x̄ ± (1.96 × SE) => if x̄ = sample mean = 550 and SE = standard \n",
    "# error = 12.8 => 95% CI [525, 575]. This example means that the central mean of the calculated variable for a sample\n",
    "# of a population is expected to stay between 525 and 575 with a 95% probability, though the current mean is 550. Using\n",
    "# gives less work to the user as he gets the info already calculated, while when having the standard error alongside\n",
    "# the mean (as above exemplified), the user still has to do a sum and subtraction to have the error limits. But, either\n",
    "# way, the usefulness of the standard error is to tell the user how trustful that arithmetic mean is and the limits he \n",
    "# should expect new calculated means to be within. The higher the \"n\", the lower tends to be the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b50d7d1e-d629-4d17-b879-c352f27e13cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_standard_error = 1.56 --- population_standard_error = 1.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.56"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating both population and sample standard errors (SE) for the data in item_price_ndarray\n",
    "population_standard_error = round(population_standard_deviation/np.sqrt(my_n),2)\n",
    "sample_standard_error = round(sample_standard_deviation/np.sqrt(my_n),2)\n",
    "print(f\"sample_standard_error = {sample_standard_error} --- population_standard_error = {population_standard_error}\")\n",
    "sample_standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "e2178b35-f492-40e7-a93b-fc12f3a9f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "5e0c2f36-cdd3-4b47-992c-b6493616665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_standard_error = 1.56 --- population_standard_error = 1.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.56"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating both population and sample standard errors (SE) for the data in item_price_ndarray\n",
    "# ddof (Delta Degrees of Freedom) of stats module defaults to 1 (sample). If population SE is desired, set ddof=0\n",
    "population_standard_error = round(stats.sem(a=item_price_ndarray, ddof=0),2)\n",
    "sample_standard_error = round(stats.sem(a=item_price_ndarray),2)\n",
    "print(f\"sample_standard_error = {sample_standard_error} --- population_standard_error = {population_standard_error}\")\n",
    "sample_standard_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aafbb9f-4e9f-468a-894d-7390f755a877",
   "metadata": {},
   "source": [
    "#### - Coefficient of Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f54708-7007-4271-b718-1961221b64cf",
   "metadata": {},
   "source": [
    "![coefficient of variation](coefficient-of-variation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "203a7632-ac7b-4893-bdae-f5fb41be64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the coefficient of variation is a dispersion measure calculated by dividing the standard deviation by the mean, that is, by comparing\n",
    "# the standard deviation of a Series of continuous numerical data, either from the whole population or from a sample of it. As such, this\n",
    "# measure reflects how disperse values are regarding the mean, and has no unit, it's a dimensionless number. Therefore, it is useful in \n",
    "# comparing dispersions at different distributions, with different units or widely different means, better than the standard deviation. It\n",
    "# can be presented as a decimal number or as a percentage, so that, the lowest its value, the closest the data series values at the \n",
    "# distribution will be to their mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "3f0db7e4-fc6d-4837-9e64-c28e8c115d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_coefficient_of_variation = 0.0819 --- population_coefficient_of_variation = 0.0815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8.19%'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating both population and sample coefficients of variation (CV) for the data in item_price_ndarray\n",
    "population_coefficient_of_variation = population_standard_deviation/my_mean\n",
    "sample_coefficient_of_variation = sample_standard_deviation/my_mean\n",
    "print(f\"sample_coefficient_of_variation = {round(sample_coefficient_of_variation,4)} --- population_coefficient_of_variation = {round(population_coefficient_of_variation,4)}\")\n",
    "sample_coefficient_of_variation_in_percent = f\"{round(sample_coefficient_of_variation*100, 2)}%\"\n",
    "sample_coefficient_of_variation_in_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b83cd-e6a5-4c4f-aeb8-34ec5b09b9d3",
   "metadata": {},
   "source": [
    "### Shape measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408754f7-ab53-4ac7-8be5-a3b7f4445451",
   "metadata": {},
   "source": [
    "#### - Coefficient of Asymmetry (Skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f69e50-05f0-4a2b-afbc-0aab7865a550",
   "metadata": {},
   "source": [
    "![coefficient of asymmetry - skewness](fisher-asymmetry.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b5708460-8535-4269-976c-d9341df6dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Fisher's coefficient of asymmetry, also known as skewness of a distribution curve, is a shape measure that tells us how distorted the \n",
    "# top of the curve is from where it would be if the distribution was a symmetrical one. In a symmetrical curve, the three central positional \n",
    "# measures are equal and perfectly centralized: mean, median and mode. In a curve skewed to the left, that is, with a g1 < 0, when we have \n",
    "# some negative outliers compared to the mean, these too negative values force the mean of the curve to the left as well, and throws the \n",
    "# median and mode to the right (mean<median<mode), so that, graphically, the tail of the curve is more prominet to the left while the top \n",
    "# is shifted to the right. The top always follows the mode, while the tail follows the mean... and the median always in between both. On \n",
    "# the other hand, a curve skewed to the right, that is, with a g1 > 0, when we have some positive outliers compared to the mean, these too \n",
    "# positive values force the mean of the curve to the right (mode<median<mean), so that, graphically, the tail of the curve is more prominent \n",
    "# to the right, while the top is shifted to the left, along with the mode and median. If the the curve has no outliers and all positive and \n",
    "# negative values are equally distributed and close to the center, making the mean, median and mode have the same values, the curve is \n",
    "# centered and the skewness is zero => g1 = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "10535698-2d56-4402-9473-791fae6ab3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0899"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the skewness (coefficient of asymmetry) for the data distribution at item_price_ndarray\n",
    "my_skewness = round(stats.skew(a=item_price_ndarray, bias=False), 4)\n",
    "my_skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e42373-b950-4176-a59e-d57050c5b57a",
   "metadata": {},
   "source": [
    "#### - Coefficient of Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df141dce-82c1-4e1b-bf37-7ca4bd3704e6",
   "metadata": {},
   "source": [
    "![coefficient of kurtosis](fisher-kurtosis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "b2e0db4a-8a13-4bc9-80c9-3d981b787933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Fisher's coefficient of kurtosis is another shape measure that refers to the flattening of the distribution curve. The more the \n",
    "# curve is flattened compared to the original curve, the more disperse its values are regarding the mean, while, on the contrary, when\n",
    "# the curve is narrowed (deflattened) when compared to the original curve, its values tend to be closer and less disperse compared to\n",
    "# the mean value. Kurtosis measures the outliers (extremes) of a distribution... and is poorly affected by central values. Distribution\n",
    "# curves with zero excess kurtosis (g2=0) are called mesokurtic; distribution curves with positive excess kurtosis are called leptokurtic \n",
    "# (g2>0); while distribution curves with negative excess kurtosis (g2<0) are called platykurtic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b25343b7-2143-4155-b124-4ab052567fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6695"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the coefficient of kurtosis for the data distribution at item_price_ndarray\n",
    "my_kurtosis = round(stats.kurtosis(a=item_price_ndarray, bias=False), 4)\n",
    "my_kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a017575-988d-4664-82e5-f1fca8064ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
